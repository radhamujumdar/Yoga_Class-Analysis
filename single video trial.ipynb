{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f18a41c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow_docs.vis import embed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "# Import matplotlib libraries\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "01795482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D:/BE/Project/test_videos\\\\nidhip.mp4']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "\n",
    "def create_dir(path):\n",
    "    try:\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "    except OSError:\n",
    "        print(f\"ERROR: creating directory with name {path}\")\n",
    "def save_frame(video_path, gap=30):\n",
    "    \n",
    "    save_path=\"frames\"\n",
    "    create_dir(save_path)\n",
    "#     print(\"yes\")\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "#     print(\"yes again\")\n",
    "    #fps = cap.get( cv2.CAP_PROP_FPS ) \n",
    "    #print(fps)\n",
    "    idx = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if ret == False:\n",
    "            cap.release()\n",
    "            break\n",
    "\n",
    "        if (idx>=15 and (idx-gap//2) % gap == 0):\n",
    "            #image=img_crop(frame)\n",
    "            cv2.imwrite(f\"{save_path}/{idx}.png\", frame)\n",
    "\n",
    "        idx += 1\n",
    "if __name__ == \"__main__\":\n",
    "    video_paths = glob(\"D:/BE/Project/test_videos/*\")\n",
    "    print(video_paths)\n",
    "#     save_dir = \"geet_dataset2/train/\"\n",
    "    for path in video_paths:\n",
    "        save_frame(path, gap=60)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "99ad65dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_movenet(path):\n",
    "    image_path =path\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.compat.v1.image.decode_jpeg(image)\n",
    "    image = tf.expand_dims(image, axis=0)\n",
    "    # Resize and pad the image to keep the aspect ratio and fit the expected size.\n",
    "    image = tf.cast(tf.image.resize_with_pad(image, 192, 192), dtype=tf.int32)\n",
    "\n",
    "    # Download the model from TF Hub.\n",
    "    model = hub.load(\"https://tfhub.dev/google/movenet/singlepose/lightning/4\")\n",
    "    movenet = model.signatures['serving_default']\n",
    "\n",
    "    # Run model inference.\n",
    "    outputs = movenet(image)\n",
    "# Output is a [1, 1, 17, 3] tensor.\n",
    "    keypoints = outputs['output_0']\n",
    "    kpts_x = keypoints[0, 0, :, 0]\n",
    "    kpts_y = keypoints[0, 0, :, 1]\n",
    "    kpts_scores = keypoints[0, 0, :, 2]\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "     # Empty dataset\n",
    "    t_x=kpts_x.numpy()\n",
    "    t_y=kpts_y.numpy()\n",
    "    \n",
    "    tn=[]\n",
    "   \n",
    "    for i in range(0,17):\n",
    "        tn.append(t_x[i])\n",
    "        tn.append(t_y[i])\n",
    "    return tn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e2ca65d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\BE\\Project\\Yoga_Class-Analysis\\frames\\30.png\n",
      "D:\\BE\\Project\\Yoga_Class-Analysis\\frames\\90.png\n",
      "D:\\BE\\Project\\Yoga_Class-Analysis\\frames\\150.png\n",
      "D:\\BE\\Project\\Yoga_Class-Analysis\\frames\\210.png\n",
      "D:\\BE\\Project\\Yoga_Class-Analysis\\frames\\270.png\n",
      "D:\\BE\\Project\\Yoga_Class-Analysis\\frames\\330.png\n",
      "D:\\BE\\Project\\Yoga_Class-Analysis\\frames\\390.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "path_lst=[]\n",
    "\n",
    "keypts_inner_test=[]\n",
    "keypts_outer_test=[]\n",
    "\n",
    "\n",
    "\n",
    "for image in os.listdir('frames'):\n",
    "    path_lst.append(os.path.abspath(f\"frames/{image}\"))\n",
    "        \n",
    "        #path_lst_per.append(path_lst)\n",
    "        #image_path_dictionary[name] = path_list\n",
    "              \n",
    "path_lst = sorted(path_lst,key=os.path.getmtime)\n",
    "\n",
    "for path in path_lst:\n",
    "    print(path)\n",
    "    keypts_inner_test=image_to_movenet(path)\n",
    "    keypts_outer_test.append(keypts_inner_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6f8453ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.40834564, 0.5285305, 0.39134464, 0.5442334, 0.38715324, 0.5182702, 0.37302798, 0.55452317, 0.3697573, 0.4980904, 0.39781296, 0.5772733, 0.4077251, 0.45367104, 0.4871038, 0.6016332, 0.50545853, 0.46478093, 0.5489899, 0.62707263, 0.58423316, 0.5034302, 0.55806273, 0.55844676, 0.5552764, 0.47660667, 0.6060969, 0.6352718, 0.5743242, 0.38505667, 0.6207972, 0.5047588, 0.6218187, 0.5169618], [0.4081831, 0.5374985, 0.3906402, 0.54796886, 0.3895032, 0.5239401, 0.3733064, 0.5587251, 0.37315452, 0.50427896, 0.40029693, 0.5769456, 0.40843612, 0.46444452, 0.49382967, 0.6182232, 0.50727326, 0.44754368, 0.5183125, 0.64773184, 0.5217031, 0.5506582, 0.5507156, 0.5506505, 0.5520171, 0.47612762, 0.57405996, 0.60297275, 0.55776083, 0.45229012, 0.6134355, 0.50586057, 0.60618657, 0.5130745], [0.39216763, 0.4844072, 0.37958443, 0.49777555, 0.38130778, 0.47490558, 0.36241361, 0.52178633, 0.3702756, 0.4706586, 0.40500474, 0.55737007, 0.40208387, 0.445261, 0.52325904, 0.5519822, 0.503337, 0.42675436, 0.6047616, 0.5191964, 0.5822462, 0.42723405, 0.5493582, 0.5502149, 0.54710823, 0.4685021, 0.5824503, 0.6279577, 0.5809297, 0.39914626, 0.6243273, 0.5203191, 0.61044943, 0.49577352], [0.40679893, 0.4809113, 0.39163822, 0.497622, 0.39191157, 0.47357225, 0.36926958, 0.51671493, 0.37421244, 0.46644175, 0.39933455, 0.5614723, 0.40559694, 0.4390546, 0.48793066, 0.5775096, 0.49167866, 0.41499838, 0.54755545, 0.51113236, 0.54680574, 0.44842288, 0.55498123, 0.54219, 0.55627733, 0.45965955, 0.57031107, 0.5973125, 0.5990151, 0.35712975, 0.5794401, 0.48633337, 0.5803033, 0.48398036], [0.3746274, 0.51645494, 0.3638062, 0.52882165, 0.36211464, 0.50341713, 0.36331546, 0.5391953, 0.3627667, 0.48350698, 0.40986764, 0.5690146, 0.40471733, 0.44484067, 0.5006579, 0.59027517, 0.49776518, 0.42841876, 0.5666839, 0.6035952, 0.57436234, 0.46174055, 0.57312316, 0.54390126, 0.5683147, 0.46357557, 0.6238121, 0.6208935, 0.62518144, 0.34212655, 0.60889524, 0.49503332, 0.6086954, 0.4916005], [0.36158773, 0.5041225, 0.3498823, 0.5179329, 0.35027522, 0.4943441, 0.35934758, 0.5333691, 0.3586337, 0.47877786, 0.41192138, 0.5666777, 0.4051585, 0.4441608, 0.5036664, 0.5831455, 0.5080441, 0.42843705, 0.57030714, 0.6021954, 0.56579113, 0.42883703, 0.5833316, 0.5493572, 0.5765684, 0.46446094, 0.6151469, 0.619402, 0.626055, 0.33550388, 0.6076832, 0.48381147, 0.6068301, 0.49189553], [0.366793, 0.50689995, 0.35775214, 0.5201414, 0.35593995, 0.49789888, 0.36396223, 0.5346117, 0.3610959, 0.48082274, 0.41444135, 0.5674672, 0.40845317, 0.44417652, 0.51690686, 0.5868748, 0.51525486, 0.42568013, 0.5764858, 0.5991965, 0.57295847, 0.44524142, 0.58247745, 0.54713094, 0.5759846, 0.46219045, 0.6236541, 0.6217653, 0.6234133, 0.33717474, 0.6088723, 0.48392874, 0.6085017, 0.49257216]]\n"
     ]
    }
   ],
   "source": [
    "print(keypts_outer_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "63ab7772",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Masking\n",
    "def padding_masking(x_test):\n",
    "    testing=[]\n",
    "    for i in range(0,1):\n",
    "        result = np.zeros((77, 34))\n",
    "        result[:np.array(x_test[0]).shape[0],:np.array(x_test[0]).shape[0]]=x_test[0]\n",
    "        testing.append(result)\n",
    "    x_test=tf.convert_to_tensor(testing,dtype='float32')\n",
    "    mask_layer=Masking(mask_value=0.0)\n",
    "    x_test=mask_layer(x_test)\n",
    "    return x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8cb66307",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=keypts_outer_test\n",
    "x_test=np.array(x_test)\n",
    "x_test.shape[0]\n",
    "x_test=padding_masking(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ec2d376e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 77, 34)\n"
     ]
    }
   ],
   "source": [
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59110f34",
   "metadata": {},
   "source": [
    "load model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "bbaeed85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.6049933  6.7246857 -1.5302136 -2.9431598  3.8076189 -3.437937 ]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import LSTM\n",
    "# It can be used to reconstruct the model identically.\n",
    "model = keras.models.load_model(\"savemodel.h5\")\n",
    "\n",
    "# Let's check:\n",
    "# np.testing.assert_allclose(\n",
    "#     model.predict(test_input), reconstructed_model.predict(test_input)\n",
    "# )\n",
    "\n",
    "# The reconstructed model is already compiled and has retained the optimizer\n",
    "# state, so training can resume:\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065ac039",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4848b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
